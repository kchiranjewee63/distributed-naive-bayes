{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fea4515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import split, explode\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import sum as _sum\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a86215",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SentimentAnalysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c920ee04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-2C3NPD0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SentimentAnalysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1b99145b520>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caaef03",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69dfed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews_df = spark.read.csv(\"IMDB Dataset.csv\", header=True, inferSchema=True, quote='\"', escape='\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee0b9d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movie_reviews_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2e58080",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.01, 0.99] # 70% for training, 30% for testing\n",
    "training_data, testing_data = movie_reviews_df.randomSplit(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b890eab",
   "metadata": {},
   "source": [
    "# Count the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31fcd4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(data):\n",
    "    counts = data.groupBy('sentiment').count()\n",
    "    return counts.rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729501c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels counts: {'positive': 241, 'negative': 234}\n",
      "Testing labels counts: {'positive': 24759, 'negative': 24766}\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "training_labels_counts = count_labels(training_data)\n",
    "print(\"Training labels counts:\", training_labels_counts)\n",
    "\n",
    "#Testing\n",
    "testing_labels_counts = count_labels(testing_data)\n",
    "print(\"Testing labels counts:\", testing_labels_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def875e3",
   "metadata": {},
   "source": [
    "# Count the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afff0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_count_in_a_class(reviews_data_frame, class_label):\n",
    "    class_reviews = reviews_data_frame.filter(reviews_data_frame.sentiment == class_label)\n",
    "    words_column = explode(split(class_reviews.review, \"\\s+\")).alias(\"word\")\n",
    "    words_counts = class_reviews.select(words_column).groupBy(\"word\").count()\n",
    "    total_count = words_counts.agg(_sum('count')).collect()[0][0]\n",
    "    words_counts = words_counts.rdd.collectAsMap()\n",
    "    return {\"total-count\":total_count, \"words-counts\":words_counts}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21594ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "pos_counts = get_words_count_in_a_class(training_data, \"positive\")\n",
    "pos_counts[\"class-prob\"] = training_labels_counts['positive']/(training_labels_counts['positive'] + training_labels_counts['negative'])\n",
    "neg_counts = get_words_count_in_a_class(training_data, \"negative\")\n",
    "neg_counts[\"class-prob\"] = training_labels_counts['negative']/(training_labels_counts['positive'] + training_labels_counts['negative'])\n",
    "\n",
    "# Testing\n",
    "test_pos_counts = get_words_count_in_a_class(testing_data, \"positive\")\n",
    "test_pos_counts[\"class-prob\"] = testing_labels_counts['positive']/(testing_labels_counts['positive'] + testing_labels_counts['negative'])\n",
    "test_neg_counts = get_words_count_in_a_class(testing_data, \"negative\")\n",
    "test_neg_counts[\"class-prob\"] = testing_labels_counts['negative']/(testing_labels_counts['positive'] + testing_labels_counts['negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e3bb8f",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80a87781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob_calculator(review, class_count):\n",
    "        words = review.split()\n",
    "        probs_list = [class_count[\"words-counts\"].get(word, 1)/class_count[\"total-count\"] for word in words]\n",
    "        return log(class_count['class-prob']) + reduce(lambda a, b: a + log(b), probs_list, 0)\n",
    "\n",
    "def create_predictor(pos_count_bc, neg_count_bc):\n",
    "    def predictor(review):\n",
    "        pos_log_prob = log_prob_calculator(review, pos_count_bc.value)\n",
    "        neg_log_prob = log_prob_calculator(review, neg_count_bc.value)\n",
    "        return 'positive' if pos_log_prob > neg_log_prob else 'negative'\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357fa3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(data, pos_counts, neg_counts):\n",
    "    pos_count_bc = spark.sparkContext.broadcast(pos_counts)\n",
    "    neg_count_bc = spark.sparkContext.broadcast(neg_counts)\n",
    "\n",
    "    predictor_udf = udf(create_predictor(pos_count_bc, neg_count_bc), StringType())\n",
    "\n",
    "    predictions = training_data.withColumn('prediction', predictor_udf(data.review))\n",
    "\n",
    "    accuracy = predictions.filter(predictions.sentiment == predictions.prediction).count()/training_data.count()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training predictions and accuracy\n",
    "cal_accuracy(training_data, pos_counts, neg_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "533b98ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8363709078443695\n"
     ]
    }
   ],
   "source": [
    "# Test predictions and accuracy\n",
    "pos_count_bc = spark.sparkContext.broadcast(test_pos_counts)\n",
    "neg_count_bc = spark.sparkContext.broadcast(test_neg_counts)\n",
    "\n",
    "predictor_udf = udf(create_predictor(pos_count_bc, neg_count_bc), StringType())\n",
    "\n",
    "predictions = training_data.withColumn('prediction', predictor_udf(testing_data.review))\n",
    "\n",
    "accuracy = predictions.filter(predictions.sentiment == predictions.prediction).count()/training_data.count()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3cde0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
